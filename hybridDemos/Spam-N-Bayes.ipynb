{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spam-N-Bayes \n",
    "**An Introduction to the Watson Machine Learning Python Client** <br> <br>\n",
    "This tutorial will show you how to build a deploy an SMS Spam Classifer with Watson Machine Learning and IBM Data Science Experience. <br> We'll use the new [Watson Machine Learning API Client for Python](http://wml-api-pyclient.mybluemix.net/) which is avialable on `PyPi`. \n",
    "______\n",
    "This notebook runs on `Python 3.5` with any `Spark` version. \n",
    "This notebook can be used as a companion to another [tutorial on our blog](https://medium.com/@adammassachi/dsx-hybrid-mode-91b580450c5b).  <br>\n",
    "[Get the data](https://apsportal.ibm.com/exchange/public/entry/view/e39fb7848165baca7fc0395025ba4e48). \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Load data](#load)\n",
    "2. [Build model](#build)\n",
    "3. [Save and deploy](#save)\n",
    "4. [Make API requests](#api)\n",
    "\n",
    "_____\n",
    "\n",
    "## 1. Load data <a id=\"load\"></a>\n",
    "First, install the Watson Machine Learning library via `pip` if you have not yet installed it. <br> We'll use this library to communicate with Watson Machine Learning. The `python client` allows anyone with a Watson Machine Learning instance to programmatically save, load, and deploy models, among other tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are SMS Messages which have been labeled `spam` or `ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you'll need to get the data and add it to your DSX project or local environment \n",
    "\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# @hidden_cell\n",
    "# This function accesses a file in your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def get_object_storage_file_with_credentials_051057ada6f24724b4e68c3152e92f7e(container, filename):\n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': 'member_32ee99828223dae28f6f4ef55bb69120ea9f3d52','domain': {'id': '04144f60bfe64c0d9fdfb632799cf206'},\n",
    "            'password': 'A.2-e~Zx6t)9O~BT'}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return StringIO(resp2.text)\n",
    "df = pd.read_csv(get_object_storage_file_with_credentials_051057ada6f24724b4e68c3152e92f7e('hybridDemos', 'spam.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be converting the string label into a numeric representation. <br> \n",
    "We can use a `pandas.Series method`,  `factorize()[0]`, to convert strings into numeric factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.columns[:2]]\n",
    "df.columns = ['ham', 'text']\n",
    "df['label'] = df.ham.factorize()[0]\n",
    "df['text'] = df.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ham                                               text  label\n",
       "0   ham  go until jurong point, crazy.. available only ...      0\n",
       "1   ham                      ok lar... joking wif u oni...      0\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...      1\n",
       "3   ham  u dun say so early hor... u c already then say...      0\n",
       "4   ham  nah i don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build\"></a>\n",
    "## 2. Build a model \n",
    "We're going to use `scikit-learn` to create a `Naive Bayes` model. <br>We’ll use the `HashingVectorizer`, which converts the SMS’ text into a matrix representation suitable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vectorizer = HashingVectorizer(n_features=5000, stop_words='english', non_negative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need connect the output of the `vectorizer` to the input of the model. We’ll use `Multinomial Naive Bayes`. It’s a Naive Bayes classifier which works well with the representation of our features — integer representations of the word frequencies.\n",
    "\n",
    "\n",
    "Next, we’ll use `train_test_split` in order to divide the data into `testing` and `training` sets so that we can evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to transform the text and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first transform the text data\n",
    "transformed_x = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# import the modules and fit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bn = MultinomialNB().fit(transformed_x, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve got a fit model in `bn`. Let’s evalue the performance on the test data after creating the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a pipe\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vectorizer, bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe will sequentially transform the data according to the transformers specified, terminating in what scikit-learn calls an estimator. <br>Then, we can call predict or score, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80165557,  0.19834443]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95405599425699927"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`96% accuracy`, not bad. You can experiement with different numbers of features and vectorizers for your model. You can also create other features that are not captured by the vectorizer, such as the length of the message. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## 3. Save and deploy\n",
    "Use the client to save your model to the WML Repository. From there, you can load and deploy models as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_credentials = {\n",
    "  \"url\": \"https://ibm-watson-ml.mybluemix.net\",\n",
    " \"access_key\": \"p4och04zC8JgoPyT4CZyrPArLm8tT01vAKuwRfBUuBhy0Ex14vUTrK3u85i94r5YHxGxQ3pIogjgEOjN0TGDTcL0h32gVzPkwMbmHXNpi+FQYUqQmv73SQJrb1WXWeZv\",\n",
    "  \"username\": \"a90b3ea8-1bbb-48b8-b8e4-d71fb8902b5d\",\n",
    "  \"password\": \"ebeafa46-9b6d-4beb-9070-f42d7feb1286\",\n",
    "  \"instance_id\": \"0b917078-2507-4590-b152-9904dfdff9d9\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<watson_machine_learning_client.libs.repository.mlrepositoryclient.model_adapter.ScikitModelArtifact at 0x7fd605623da0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# publish model \n",
    "client.repository.publish(pipe, name=\"Spam-N-Bayes-py3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've published the model to the repository, we can load it into a python object using it's `uid`. First, let's look at the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get my repository details\n",
    "deets = client.repository.get_details()\n",
    "\n",
    "# got to the model respources, find the first model, go to the metadata, get the `id`\n",
    "model_id = deets['resources'][0]['metadata']['guid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 0,\n",
       " 'url': 'https://ibm-watson-ml.mybluemix.net/v3/wml_instances/0b917078-2507-4590-b152-9904dfdff9d9/published_models/23de8978-33a1-4d23-a3e4-e010c8fdb656/deployments'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deets['resources'][0]['entity']['deployments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = client.repository.load(model_id)\n",
    "type(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': '2017-10-11T16:48:40.576Z',\n",
       " 'guid': '23de8978-33a1-4d23-a3e4-e010c8fdb656',\n",
       " 'modified_at': '2017-10-11T16:48:40.837Z',\n",
       " 'url': 'https://ibm-watson-ml.mybluemix.net/v3/wml_instances/0b917078-2507-4590-b152-9904dfdff9d9/published_models/23de8978-33a1-4d23-a3e4-e010c8fdb656'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deets['resources'][0]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80165557,  0.19834443]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that it's the same\n",
    "mod.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"api\"></a>\n",
    "## 4. Test the API\n",
    "Now that we've successfully saved and loaded the model, we can create an API endpoint and make requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.create(model_id, name=\"SPAMO\", description=\"Spam model deployed from notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some JSON to send. We'll use `client.deployments.score(scoring_url, payload)`. [Read our docs](http://wml-api-pyclient.mybluemix.net/) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a payload\n",
    "my_sms = \"Send me to the API por favor\"\n",
    "payload = {\"values\": [my_sms]}\n",
    "\n",
    "# make a request\n",
    "response = client.deployments.score(scoring_endpoint, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'probability'],\n",
       " 'values': [[0, [0.8164689448418778, 0.1835310551581235]]]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference the [blog](https://medium.com/p/91b580450c5b/edit).\n",
    "\n",
    "____________\n",
    "\n",
    "### Author\n",
    "Adam Massachi is a Data Scientist with the Data Science Experience and Watson Data Platform teams at IBM. Before IBM, he worked on political campaigns, building and managing large volunteer operations and organizing campaign finance initiatives. Say hello [@adammassach](https://twitter.com/adammassach?lang=en)!\n",
    "\n",
    "### Citations\n",
    "\n",
    "City of Chicago (2017). Building Violations <a href=https://data.cityofchicago.org/Buildings/Building-Violations/22u3-xenr target=\"_blank\" rel=\"noopener noreferrer\">https://data.cityofchicago.org/Buildings/Building-Violations/22u3-xenr</a>  Chicago, IL: Chicago City Data Portal\n",
    "\n",
    "Copyright © IBM Corp. 2017. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
